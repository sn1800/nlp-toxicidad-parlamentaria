{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec6d528",
   "metadata": {},
   "source": [
    "# üìí Toxicidad ES ‚Äî Entrenar sin `evaluation_strategy`\n",
    "Se entrena con `dataset_diverso_10000.csv` y luego se eval√∫a manualmente (validaci√≥n y Congreso) **sin usar** el par√°metro `evaluation_strategy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70025225",
   "metadata": {},
   "source": [
    "## 0) Instalar dependencias (si hace falta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta SOLO si no tienes estas versiones instaladas o est√°s en Colab.\n",
    "!pip -q install -U transformers datasets evaluate scikit-learn accelerate torch pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830b952",
   "metadata": {},
   "source": [
    "## 1) Imports, configuraci√≥n y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9743cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluate\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "import torch\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "RUNS_DIR = Path(\"runs\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "for d in [DATA_DIR, RUNS_DIR, MODELS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103c19b",
   "metadata": {},
   "source": [
    "## 2) Cargar `dataset_diverso_10000.csv` y crear splits (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467a76e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 3), (1500, 3), (1500, 3), {1: 3500, 0: 3500})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CSV = DATA_DIR / \"dataset_diverso_10000.csv\"\n",
    "assert BASE_CSV.exists(), f\"No encuentro el archivo: {BASE_CSV}\"\n",
    "\n",
    "df = pd.read_csv(BASE_CSV)\n",
    "\n",
    "# Detectar columnas de texto/label y normalizar\n",
    "text_col = next((c for c in df.columns if c.lower() in [\"text\",\"texto\",\"sentence\"]), None)\n",
    "label_col = next((c for c in df.columns if c.lower() in [\"label\",\"etiqueta\",\"tag\"]), None)\n",
    "assert text_col and label_col, f\"No encuentro columnas de texto/label en {df.columns.tolist()}\"\n",
    "\n",
    "df = df.rename(columns={text_col: \"texto\", label_col: \"label\"})\n",
    "\n",
    "def map_label(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in [\"toxico\",\"1\",\"toxic\",\"toxico.\"]:\n",
    "        return 1\n",
    "    return 0\n",
    "df[\"label\"] = df[\"label\"].map(map_label).astype(int)\n",
    "\n",
    "train_df, tmp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=SEED, stratify=df[\"label\"]\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df, test_size=0.50, random_state=SEED, stratify=tmp_df[\"label\"]\n",
    ")\n",
    "\n",
    "train_df.to_csv(DATA_DIR / \"train_diverso.csv\", index=False)\n",
    "val_df.to_csv(DATA_DIR / \"val_diverso.csv\", index=False)\n",
    "test_df.to_csv(DATA_DIR / \"test_diverso.csv\", index=False)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape, train_df['label'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47131c",
   "metadata": {},
   "source": [
    "## 3) Tokenizar (BETO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f7c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7000/7000 [00:00<00:00, 37374.77 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:00<00:00, 80042.95 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:00<00:00, 74875.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'texto', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'texto', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'texto', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "MAX_LEN = 256\n",
    "NUM_LABELS = 2\n",
    "\n",
    "train = Dataset.from_pandas(pd.read_csv(DATA_DIR / \"train_diverso.csv\"))\n",
    "val   = Dataset.from_pandas(pd.read_csv(DATA_DIR / \"val_diverso.csv\"))\n",
    "test  = Dataset.from_pandas(pd.read_csv(DATA_DIR / \"test_diverso.csv\"))\n",
    "\n",
    "ds = DatasetDict(train=train, validation=val, test=test)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "def tok_fn(examples):\n",
    "    return tokenizer(examples[\"texto\"], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "ds = ds.map(tok_fn, batched=True)\n",
    "ds = ds.rename_column(\"label\", \"labels\")\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecb23f",
   "metadata": {},
   "source": [
    "## 4) *Class weights* (si hay desbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569bf780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de clases (train): {0: np.int64(3500), 1: np.int64(3500)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(DATA_DIR / \"train_diverso.csv\")[\"label\"].values\n",
    "classes = np.unique(y_train)\n",
    "class_counts = np.bincount(y_train)\n",
    "print(\"Distribuci√≥n de clases (train):\", dict(enumerate(class_counts)))\n",
    "\n",
    "total = class_counts.sum()\n",
    "class_weights = torch.tensor([total / (len(classes) * c) if c > 0 else 0.0 for c in class_counts], dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06472882",
   "metadata": {},
   "source": [
    "## 5) Modelo y `Trainer` (sin `evaluation_strategy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcb50cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fernando\\AppData\\Local\\Temp\\ipykernel_21476\\1309764010.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WeightedTrainer at 0x29f1f451090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, num_labels=NUM_LABELS)\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1  = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"f1_weighted\": metric_f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model,\n",
    "        inputs,\n",
    "        return_outputs: bool = False,\n",
    "        num_items_in_batch: int | None = None,   # <-- clave para versiones nuevas\n",
    "        **kwargs,                                 # <-- y por si cambian algo m√°s\n",
    "    ):\n",
    "        # No mutar inputs originales\n",
    "        labels = inputs[\"labels\"]\n",
    "        model_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n",
    "\n",
    "        outputs = model(**model_inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# üîß No usamos evaluation_strategy ni load_best_model_at_end\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(RUNS_DIR / \"beto-toxic-diverso-no-evalstrategy\"),\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    # save_strategy='no',  # opcional: sin checkpoints\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    # eval_dataset omitido para evitar cualquier evaluaci√≥n durante train\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5e63a",
   "metadata": {},
   "source": [
    "## 6) Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b5fdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1314/1314 16:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fernando\\OneDrive\\Documentos\\Proyectos\\NLP\\nlp-toxicidad-parlamentaria\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 965.0561,\n",
       " 'train_samples_per_second': 21.76,\n",
       " 'train_steps_per_second': 1.362,\n",
       " 'total_flos': 272303497856640.0,\n",
       " 'train_loss': 0.004102648006659285,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "train_result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140210b",
   "metadata": {},
   "source": [
    "## 7) Evaluaci√≥n manual en validaci√≥n y test (despu√©s del entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a218dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fernando\\OneDrive\\Documentos\\Proyectos\\NLP\\nlp-toxicidad-parlamentaria\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas (validaci√≥n): {'eval_loss': 1.7539823602419347e-05, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_f1_weighted': 1.0, 'eval_runtime': 13.4982, 'eval_samples_per_second': 111.126, 'eval_steps_per_second': 3.482, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fernando\\OneDrive\\Documentos\\Proyectos\\NLP\\nlp-toxicidad-parlamentaria\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas (test): {'eval_loss': 1.7515505533083342e-05, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_f1_weighted': 1.0, 'eval_runtime': 11.6756, 'eval_samples_per_second': 128.473, 'eval_steps_per_second': 4.025, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fernando\\OneDrive\\Documentos\\Proyectos\\NLP\\nlp-toxicidad-parlamentaria\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (test-diverso):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       750\n",
      "           1     1.0000    1.0000    1.0000       750\n",
      "\n",
      "    accuracy                         1.0000      1500\n",
      "   macro avg     1.0000    1.0000    1.0000      1500\n",
      "weighted avg     1.0000    1.0000    1.0000      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validaci√≥n\n",
    "eval_val = trainer.evaluate(ds[\"validation\"])\n",
    "print(\"M√©tricas (validaci√≥n):\", eval_val)\n",
    "\n",
    "# Test\n",
    "eval_test = trainer.evaluate(ds[\"test\"])\n",
    "print(\"M√©tricas (test):\", eval_test)\n",
    "\n",
    "# Reporte en test\n",
    "pred_out = trainer.predict(ds[\"test\"])\n",
    "logits = pred_out.predictions\n",
    "y_true = pred_out.label_ids\n",
    "y_pred = logits.argmax(-1)\n",
    "\n",
    "print(\"\\nClassification report (test-diverso):\\n\")\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f29dc8",
   "metadata": {},
   "source": [
    "## 8) Guardar modelo, tokenizer y m√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = MODELS_DIR / \"beto-toxicidad-diverso-no-evalstrategy\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trainer.save_model(str(SAVE_DIR))\n",
    "tokenizer.save_pretrained(str(SAVE_DIR))\n",
    "\n",
    "with open(SAVE_DIR / \"metrics_test_diverso.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k,v in eval_test.items()}, f, indent=2)\n",
    "\n",
    "print(\"Guardado en:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a023d8",
   "metadata": {},
   "source": [
    "## 9) Evaluaci√≥n *out-of-domain* en `intervenciones_2020_17.csv` (Congreso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONG_CSV = DATA_DIR / \"intervenciones_2020_17.csv\"\n",
    "assert CONG_CSV.exists(), f\"No encuentro el archivo: {CONG_CSV}\"\n",
    "\n",
    "df_eval = pd.read_csv(CONG_CSV)\n",
    "\n",
    "text_col = next((c for c in df_eval.columns if c.lower() in [\"text\",\"texto\",\"sentence\"]), None)\n",
    "label_col = next((c for c in df_eval.columns if c.lower() in [\"label\",\"etiqueta\",\"tag\"]), None)\n",
    "assert text_col and label_col, f\"No encuentro columnas de texto/label en {df_eval.columns.tolist()}\"\n",
    "\n",
    "df_eval = df_eval.rename(columns={text_col: \"texto\", label_col: \"label\"})\n",
    "\n",
    "def map_label_eval(x):\n",
    "    s = str(x).strip().lower()\n",
    "    if s in [\"toxico\",\"1\",\"toxic\",\"toxico.\"]:\n",
    "        return 1\n",
    "    if s in [\"no_toxico\",\"0\",\"not_toxic\",\"no-toxico\"]:\n",
    "        return 0\n",
    "    try:\n",
    "        return int(float(s))\n",
    "    except:\n",
    "        return 0\n",
    "df_eval[\"label\"] = df_eval[\"label\"].map(map_label_eval).astype(int)\n",
    "\n",
    "ds_eval = Dataset.from_pandas(df_eval)\n",
    "ds_eval = ds_eval.map(lambda ex: tokenizer(ex[\"texto\"], truncation=True, max_length=MAX_LEN), batched=True)\n",
    "ds_eval = ds_eval.rename_column(\"label\", \"labels\")\n",
    "ds_eval.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "eval_congreso = trainer.evaluate(ds_eval)\n",
    "print(\"M√©tricas (Congreso OOD):\", eval_congreso)\n",
    "\n",
    "pred_out_c = trainer.predict(ds_eval)\n",
    "logits_c = pred_out_c.predictions\n",
    "y_true_c = pred_out_c.label_ids\n",
    "y_pred_c = logits_c.argmax(-1)\n",
    "\n",
    "print(\"\\nClassification report (Congreso):\\n\")\n",
    "print(classification_report(y_true_c, y_pred_c, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_true_c, y_pred_c)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Matriz de confusi√≥n ‚Äî Congreso\")\n",
    "plt.xticks([0,1], [\"No t√≥xico\",\"T√≥xico\"])\n",
    "plt.yticks([0,1], [\"No t√≥xico\",\"T√≥xico\"])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046f3c8",
   "metadata": {},
   "source": [
    "## 10) Inferencia r√°pida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "clf = AutoModelForSequenceClassification.from_pretrained(SAVE_DIR)\n",
    "tok = AutoTokenizer.from_pretrained(SAVE_DIR)\n",
    "clf.eval()\n",
    "\n",
    "def predict_toxicidad(textos, batch_size=32, threshold=0.5):\n",
    "    if isinstance(textos, str):\n",
    "        textos = [textos]\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(textos), batch_size):\n",
    "            batch = textos[i:i+batch_size]\n",
    "            enc = tok(batch, truncation=True, max_length=MAX_LEN, padding=True, return_tensors=\"pt\")\n",
    "            if torch.cuda.is_available():\n",
    "                enc = {k: v.cuda() for k, v in enc.items()}\n",
    "                clf.cuda()\n",
    "            out = clf(**enc).logits\n",
    "            proba = torch.softmax(out, dim=1).cpu().numpy()[:,1]\n",
    "            all_scores.extend(proba.tolist())\n",
    "    preds = (np.array(all_scores) >= threshold).astype(int).tolist()\n",
    "    return {\"y_pred\": preds, \"score_tox\": all_scores}\n",
    "\n",
    "predict_toxicidad([\n",
    "    \"Se ruega respeto en esta sala, no toleraremos insultos.\",\n",
    "    \"C√°llate de una vez, ignorante.\"\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
